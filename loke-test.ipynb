{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools\n",
    "\n",
    "This notebook contains all the tools that will be used by the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# For AI Agent\n",
    "from smolagents import CodeAgent, OpenAIServerModel, tool, Tool\n",
    "\n",
    "# For internet searches\n",
    "from langchain_community.tools.ddg_search.tool import DuckDuckGoSearchRun\n",
    "\n",
    "# For LLMs\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM, GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key: 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\n"
     ]
    }
   ],
   "source": [
    "# Get openai key + model\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")\n",
    "print(f'OpenAI API Key: {OPENAI_API_KEY}')\n",
    "open_ai_model = 'gpt-4.1-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load an agent\n",
    "# Create the agent's brain\n",
    "ai_agent_model = OpenAIServerModel(model_id=open_ai_model, api_key=OPENAI_API_KEY)\n",
    "# Instantiate the agent\n",
    "ai_agent = CodeAgent(tools=[], add_base_tools=True, model=ai_agent_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get top headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a web search tool\n",
    "@tool\n",
    "def web_search(query: str) -> any:\n",
    "   '''\n",
    "   Searches the web for the headlines of the latest news articles\n",
    "\n",
    "   Args:\n",
    "      query: a string representing the search query\n",
    "\n",
    "   Returns:\n",
    "      any: a list of search results containing the latest news headlines\n",
    "\n",
    "   Example:\n",
    "      headlines = web_search('What is the latest headlines for AI news?')\n",
    "   '''\n",
    "   search = DuckDuckGoSearchRun()\n",
    "   return search.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'No good DuckDuckGo Search Result was found'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Test web_search method\n",
    "web_search('What is the latest headlines for AI news?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine Priority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Determine Priority\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarises the headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "summariser_model_name = 'google/flan-t5-base'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get text to summarise (Accepts (human-readable) string as input)\n",
    "text_to_summarise = \"The Imperium of Man, also called simply the Imperium, is a galaxy-spanning, interstellar Human empire, the ultimate authority for the vast majority of the Human species in the Milky Way galaxy in the 41st Millennium A.D. It is ruled by the living god who is known as the Emperor of Mankind. However, there are other humanoid species classified as Imperial citizens, mainly mutant offshoots of genetic base-line Humans who are known as Abhumans and include such Human sub-species as the Ogryns, Ratlings and Squats. The founder and ruler of the Imperium is the god-like Emperor of Mankind, the most powerful Human psyker ever born. The Emperor founded the Imperium over 10,000 Terran years ago in the late 30th Millennium during the Unification Wars on Old Earth following the apocalyptic period in Human history known as the Age of Strife.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "097861b1d5e644db9a5ba9e8bd069b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23bcdca679d045a19c8e716b6b40c793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bada415475a64eb59f58b0e84f546532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a2a03c73b8401f82780c140e58aefd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb3b5b17349746a2a6e122de4e80c197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/ipykernel/iostream.py:154: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x7bcb9bf19240>\n",
      "  self._event_pipes[threading.current_thread()] = event_pipe\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/usr/local/lib/python3.12/site-packages/ipykernel/iostream.py:154: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x7bcb9bf19470>\n",
      "  self._event_pipes[threading.current_thread()] = event_pipe\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/usr/local/lib/python3.12/site-packages/ipykernel/iostream.py:154: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x7bcb9bf19550>\n",
      "  self._event_pipes[threading.current_thread()] = event_pipe\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(summariser_model_name)\n",
    "summariser_model = AutoModelForSeq2SeqLM.from_pretrained(summariser_model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the prompt\n",
    "summariser_prompt = f'Write a short summary for this text: {text_to_summarise}'\n",
    "print(summariser_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "encoded_summariser_prompt = tokenizer(summariser_prompt, return_tensors='pt').input_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary with model \n",
    "config = GenerationConfig(\n",
    "    do_sample = True,\n",
    "    # Bigger value flattens the curve\n",
    "    temperature = 1.0,\n",
    "    #top_p = 0.8 # Top probabilities worth XX%\n",
    "    top_k = 3 # Top X headlines\n",
    ")\n",
    "\n",
    "encoded_summary = summariser_model.generate(encoded_summariser_prompt, generation_config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the summary\n",
    "decoded_summary = tokenizer.decode(encoded_summary[0], skip_special_tokens=True)\n",
    "print(decoded_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
